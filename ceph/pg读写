什么是pg
pg的数据读写流程
一个pg的多副本一致性问题
pg如何在osd间迁移，进而实现数据恢复和数据平衡

=======================================================================================================================================================
概念：
peering:
当集群发生变动（如新增/下线 OSD、重启、网络分区等），PG 中的数据副本可能分布在不同 OSD 上。这时候 Ceph 需要重新协调这些副本，
以找出哪一个副本是最新的、哪些副本需要同步，这一过程就叫 Peering（对等协商）
什么是 PG Peering？
Peering 是一个 分布式一致性协议过程，目的是让同一个 PG 的多个副本（OSD 上的）彼此“对齐”，达成一致的视图。

在 peering 过程中，每个参与副本会报告自己所拥有的 PG 的最新状态（日志、版本号、对象列表等），主 OSD（acting primary）基于这些信息决定：

哪些对象是最新的；

哪些副本需要进行恢复（recovery）或重同步（backfill）；

是否可以进入 active+clean 状态（即可对外提供服务）。

🔄 为什么需要 Peering？
因为 Ceph 是一个高度分布式系统，PG 的副本分布在多个 OSD 上，而这些副本之间可能出现以下情况：

某个 OSD 崩溃又重启，数据是否丢失？

OSDMap 变更，PG 被迁移到了其他 OSD；

有写入操作在某些副本成功，其他副本失败；

网络分区时，PG 状态可能不一致。

为了保证这些情况之后，集群仍然是强一致性的，必须进行一次 peering 来 协商“哪个是正确的 PG 状态”。

📌 Peering 触发的典型场景：
OSD 启动或重启；

OSD 崩溃或下线；

集群新增或移除 OSD；

OSDMap 更新（比如 crush map 变化）；

重新平衡（rebalance）发生；

整个集群重启。
》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》
osd map:
OSD Map 是一个由 Monitor 维护的、描述集群拓扑和 OSD 状态的映射表，包含了所有 OSD 的健康状态、PG 到 OSD 的映射规则等关键信息。

✅ OSD Map 包含哪些信息？
信息项	说明
所有 OSD 的 ID 和状态	包括每个 OSD 是否 up/down，in/out
CRUSH 映射	用于数据分布的规则（包括权重等）
PG 到 OSD 的映射	每个 PG 应该由哪些 OSD 存储副本
版本号（epoch）	每次变动都加一，确保有序更新
Pool 信息	包括 Pool 数量、PG 数量、副本数等
历史事件（如 OSD 添加）	帮助恢复时回溯状态变化

✅ 它是干嘛用的？
客户端基于 OSD Map + CRUSH 算法可以定位对象在哪个 OSD 上（无须中心路由）；

OSD 之间通过它协调 PG 所属、副本副本一致性等；

用于 PG peering、数据恢复、迁移等重要流程；

保证集群一致性和故障恢复的关键。

✅ 举个简单例子：
假设你有：

4 个 OSD：ID 为 0~3；

有一个 Pool 设置为 64 个 PG，每个 PG 保持 2 个副本；

OSD Map 会告诉你：

OSD.2 当前是 down 状态；

PG 3 的副本在 OSD.0 和 OSD.2；

PG 3 需要恢复一个副本到 OSD.1，因为 OSD.2 down；

OSD.1 目前 in，且有足够空间；

客户端查询对象 hash 为 PG 3，根据 OSD Map 得知应联系 OSD.0 读取。

》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》
一个pg中有哪些不同的对象：
head 对象：当前最新版本的数据对象；

clone 对象：表示某个快照时刻的历史数据副本（实际存储了当时的对象数据）；

snapdir 对象：用于管理一个对象的快照信息元数据（不包含实际数据）。

🔄 具体分工：
类型	内容	作用
head	当前对象的最新数据	普通读写操作针对的对象
clone	每个快照时刻的对象副本	保留对象的历史数据（可以通过快照访问）
snapdir	快照列表 + clone 映射信息	记录有哪些快照、每个快照指向哪个 clone

🔍 举个例子：
你对对象 foo 打了两个快照 snap1 和 snap2，然后继续修改对象内容。

那么 Ceph 会：

把 snap1 和 snap2 时刻的对象内容分别拷贝成两个 clone（如 foo@snap1, foo@snap2）；

把这两个 clone 的元信息（它们属于哪个快照，时间戳等）写入 foo~snapdir 对象中；

继续的写操作只影响 foo（head 对象）本身，不会影响 clone。

✅ 为什么要分开存？
clone 存数据：因为快照要支持读历史数据，必须保存当时的数据版本；

snapdir 存元数据：集中管理 clone 的映射关系、快照 ID、时间戳等，方便快照遍历和恢复。

》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》
omap 用来干什么？
OMAP 主要用于存储对象的元数据，常见的用途有：

用途	示例说明
RADOSGW 元数据存储	比如 S3 的 object tag、ACL、versioning 信息等
RBD 镜像元数据	RBD 镜像快照、层结构、映射关系
CephFS 的 inode 信息	存储 inode 对象的属性（如权限、时间戳等）
Bluestore 自身内部管理用途	记录对象状态、回滚信息等

》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》
pg 读写流程
1 ）OSD 收到客户端发送的读写请求，将其封装为一个 op 并基于其携带的 PGID 转 发至相应的 PGO 

2 ）PG 收到 op 后，完成一系列检查，所有条件均满足后，开始真正执行 op。

3 ）如果 op 只包含读操作，那么直接执行同步读（对应多副本）或者异步读（对应纠 删码）， 等待读操作完成后向客户端应答。 

4 ）如果 op 包含写操作，首先由 Primary 基于 op 生成一个针对原始对象操作的事务
及相关日志，然后将其提交至 PGBackend, 由 PGBackend 按照备份策略转化为每个 PG
实例（包含 Primary 和所有 Replica）真正需要执行的本地事务并进行分发，当 Primary 收到所有副本的写入完成应答之后，
对应的 op 执行完成，此时由 Primary 向客户端回应 写入完成

》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》
一些术语：
Acting Set 是什么？
当一个 PG（比如 pg 1.23）被映射到若干个 OSD 上时（根据 CRUSH 规则和 OSDMap），Ceph 会选出一组 OSD 来“实际执行”该 PG 的副本管理和 I/O 操作，这组 OSD 就是 Acting Set。

它包含：
Primary OSD（主副本，接收客户端请求）
Replica OSD(s)（从副本，同步主副本的写入）

为什么需要 up set？
因为 up set 是由 CRUSH 算法 + OSD map 决定的，是 PG 所属的“法定位置”：

它告诉系统 在没有故障的前提下，PG 应该在哪些 OSD 上。

它指导 peering 过程中，应该去联系哪些 OSD 获取状态。

它用于判断哪些 OSD 是 “失联的成员”，需要恢复、替换或修复。

🔹 为什么需要 acting set？
因为真实世界中 OSD 总会有宕机或丢失的可能，不能盲目信任 up set。

所以需要一个**“实际正在工作”的集合**，即 acting set：

是 peering 之后选出的、当前可用且副本一致的 OSD 集合；

所有对 PG 的 读写操作都只会在 acting set 中执行；

如果 acting set 成员少于副本数（如从 3 个降到 2 个），PG 就是 degraded 状态。

PG Peering 阶段】：建立共识，决定当前有哪些数据副本是可信的（即 acting set）
当一个 PG 所属的 OSD 重启、crash、网络变动或 OSD map 发生变化时，PG 会进入 peering 状态。

此时，系统会尝试联系 up set 中的 OSD，询问它们有没有这个 PG 的最新数据。

每个 OSD 会报告自己所持有的 PG 状态（包括 epoch、版本号等）。

Ceph 的 OSD 会根据各副本的日志、对象版本，协商出一组完整一致的 PG 副本 —— 这就是新的 acting set。

总结一句话， upset 对peering 选举有效osd 有指导作用，告诉系统中哪些osd是理论上可用的，后续peering + recover 生成 acting set 保持一致。

》》》》》》》》》》》》》》》》》》》peering + recover《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《
✅ 说明：
up set 提供“理论上应该有哪些节点参与 peering”。
acting set 是 peering 的结果，代表“实际上哪些节点持有副本”。
2️⃣ 【Recovery 阶段】：修复 acting set 和 up set 的差异
假如 peering 发现：

up set = [1, 3, 4]（理应的数据位置）

acting set = [1, 3]（实际拥有数据）

OSD.4 是空的、健康的，那么：

系统会：

从 OSD.1 或 OSD.3 把数据 复制到 OSD.4；

等复制完成后，acting set 变为 [1, 3, 4]；

这样 acting set 就与 up set 对齐了；

最终达到 clean 状态，PG 恢复健康。


        OSD map 变更 / OSD 重启 / PG 不健康
                         ↓
                  🔄 PG 进入 Peering 状态
                         ↓
        与 up set 中的 OSD 协议协商 PG 状态、版本
                         ↓
        ➤ 如果可以确定完整一致的 PG 副本
                         ↓
        ✅ Peering 成功 → 生成新的 acting set
                         ↓
        📦 Recovery 开始：补齐 acting set 到 up set

》》》》》》》》》》》》》》》》》》》》》》》》》》》》peering是如何判断哪个副本是可用的用于后续recover
找出一组副本，它们之间在对象、日志等方面的一致性足够，能够完全重构出 PG 的数据状态。这一组副本就是可恢复的“源”，后续恢复过程会基于这组副本进行。

🔍 步骤详解：
触发 peering 的时机：

OSD crash/reboot；

网络断联；

OSDMap 更新（新增/剔除 OSD）；

主动触发，比如 admin 操作。

所有 up set 中的 OSD 上报 PG 状态：
每个 OSD 上报其持有的 PG 的：

last_update: 最后一次更新的版本；

last_complete: 最后一次“完整”状态的版本；

log: 最近的操作日志（写、删除等）；

missing set: 缺失的对象版本；

object info: 对象的元信息摘要；

epoch: 这个状态在哪个 OSDMap 时有效。

主 OSD（usually primary）分析副本状态：
它会根据：

哪些 OSD 有最近的更新（last_update 最大）；

哪些 OSD 有完整的历史记录和数据（last_complete 最一致）；

哪些副本日志内容一致；

哪些副本的 missing set 最少；
来判断出哪一组副本能组合出一个可恢复的数据快照。

选出 acting set：
主 OSD 根据上面分析，选择一组“足够一致且完整”的 OSD 作为 acting set，即：

接下来读写由这组 OSD 承担；

恢复（recovery）数据也将从这组 OSD 拉取副本同步到缺失 OSD。

✅ 举个简单例子：
假设 PG 101 有 up set = [osd.1, osd.2, osd.3]，其中：

OSD	last_update	last_complete	missing
osd.1	v.100	v.100	∅
osd.2	v.100	v.100	∅
osd.3	v.98	v.98	[v.99, v.100]

osd.1 和 osd.2 持有完整的、最新的一致副本；

osd.3 缺少两次写操作。

→ 所以 osd.1 和 osd.2 会被选入 acting set，osd.3 会作为恢复目标被重新同步。

🚨 为什么不能只看版本号？
因为有时版本号虽然相同，但：

实际内容可能被损坏（bitrot）；

日志不一致（比如有的日志未落盘）；

OSD 之间 epoch 不一致（对应不同的 OSDMap 上下文）；

所以必须综合多种因素判断，不是“最大版本号优先”。

》》》》》》》》》》》》》》》》》》》》》》》》》》》》》info  log authoritative history
三者的基本含义：
1. log（操作日志）
每个 OSD 对它所持有 PG 的写操作会记录成一条日志（如：对象写入、删除、更新等）；

记录的是最近一段时间内的变更（为节省内存，旧的 log 可能已被丢弃）；

用于追踪对象的变更顺序，支持回滚/重放。

2. info（PG 状态信息）
是 PG 的元信息，包括：

last_update: 最后一个写操作的版本号；

last_complete: 最后确认一致的版本号；

log_tail: 被截断前的日志版本（日志从哪里开始）；

missing: 当前缺失的对象；

omap_digest、size_stats 等。

info 是 PG 状态的“快照”。

3. authoritative history（权威历史）
当 PG 所在 OSD 重启后，原有日志可能丢失或不完整；

为避免数据不一致，Ceph 设计了 authoritative history，它是一个更长期稳定的版本历史记录摘要；

记录的是 PG 的历史 lineage（版本演化路径），用于判断哪些 OSD 保持了可用的历史版本；

一种类似“代际信息”的机制。

🧠 协同工作流程（以 PG Peering 为例）：
➤ 1. 启动 Peering
PG 所有候选副本（up set 中的 OSD）开始上报 info + log + authoritative history。

➤ 2. Primary（主 OSD）收集数据
收集每个 OSD 提交的：

info.last_update：哪个副本数据最“新”；

log_tail：日志从哪里开始；

missing set：缺了哪些对象；

authoritative history：是否能覆盖或匹配其他 OSD 的版本演化。

➤ 3. 判断谁是“可信副本”
Primary 会比对：

谁的 log 最完整；

哪些 OSD 的 log 范围相互重叠；

是否有人丢失关键历史段（通过 authoritative history 检查）；

谁拥有 last_complete 范围一致的对象。

➤ 4. 选出 acting set，并构建 recovery plan
Primary 会选出 一组 log 连贯、info 完整、authoritative history 不缺失 的副本；

这组副本被认为是“可信副本”；

然后根据这些副本同步其它落后的 OSD。

📌 举个例子：
假设 PG 100 的 up set 为 [osd.1, osd.2, osd.3]：

OSD	log_tail	last_update	authoritative history
osd.1	v.80	v.100	从 v.0 → v.100
osd.2	v.90	v.100	从 v.10 → v.100
osd.3	v.95	v.98	丢失 v.80-v.94

osd.3 丢了早期历史，不能被信任；

osd.1 和 osd.2 虽然 log 起点不同，但 authoritative history 都包含完整链路；
→ 所以 osd.1 和 osd.2 会进入 acting set，osd.3 被标记为需要恢复。

authoritative history:
authoritative history 包含哪些信息？
它是 PG 的版本 lineage 记录，核心数据包括：

字段	含义
epoch	PG 所在 OSD 报告的某个状态快照版本
past_intervals	过去一段时间内，PG 所处的 acting set 情况（有哪些 OSD、epoch 范围）
interval boundaries	每次 acting set 变动时的分段位置
purged_snap_ids	被删除的快照 ID（用于快照一致性判断）
history.same_interval_since	从哪个 epoch 开始 acting set 没变
history.last_epoch_started	最近一次 PG 活动的 epoch

这个信息可用来判断：“这个 OSD 是不是在多个 epoch 中都一直在线并参与数据写入”。

📈 它是怎么工作的？
来看下 在 peering 过程中的作用：

OSD 启动/peering 时汇报状态

每个参与 peering 的 OSD 会上传自己的 info、log 和 authoritative history。

Primary OSD 收集所有副本的 history

它会将不同 OSD 的 past_intervals（历史 acting set）进行比较；

查看是否有“公共的历史段”，即多个 OSD 在某段时间都属于同一个 acting set；

如果有公共 history + 至少一个 OSD 的 log 是从那段开始的，那么这个 OSD 可以被信任。

弥补 log 丢失的 gap

如果某个 OSD 的 log 丢了，但它有完整的 authoritative history；

并且有其他副本的 log 能覆盖它缺失的时间段；

就可以认为这个 OSD 在那个时间段是“在场的”，其数据可以被认为是接近完整的。

用于重建 PG 一致性状态

Primary 会根据这些 history 来确定哪些副本是可信的；

然后基于这些可信副本生成新的 acting set，准备 recovery。

🧠 举个例子帮助理解：
假设 PG 20 原 acting set 是 [osd.1, osd.2, osd.3]，其中：

osd.1 重启了，log 丢了；

但它提交了 authoritative history，说明：

“我从 epoch 100 到 150 一直在 acting set 里，和 osd.2、osd.3 是一起的”。

而 osd.2 的 log 恰好从 epoch 100 开始完整，且和 osd.1 的 history 匹配。

那么 Primary OSD 就可以信任 osd.1 是数据完整的，可以作为 recovery 来源。

