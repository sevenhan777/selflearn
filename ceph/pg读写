什么是pg
pg的数据读写流程
一个pg的多副本一致性问题
pg如何在osd间迁移，进而实现数据恢复和数据平衡

=======================================================================================================================================================
概念：
peering:
当集群发生变动（如新增/下线 OSD、重启、网络分区等），PG 中的数据副本可能分布在不同 OSD 上。这时候 Ceph 需要重新协调这些副本，
以找出哪一个副本是最新的、哪些副本需要同步，这一过程就叫 Peering（对等协商）
什么是 PG Peering？
Peering 是一个 分布式一致性协议过程，目的是让同一个 PG 的多个副本（OSD 上的）彼此“对齐”，达成一致的视图。

在 peering 过程中，每个参与副本会报告自己所拥有的 PG 的最新状态（日志、版本号、对象列表等），主 OSD（acting primary）基于这些信息决定：

哪些对象是最新的；

哪些副本需要进行恢复（recovery）或重同步（backfill）；

是否可以进入 active+clean 状态（即可对外提供服务）。

🔄 为什么需要 Peering？
因为 Ceph 是一个高度分布式系统，PG 的副本分布在多个 OSD 上，而这些副本之间可能出现以下情况：

某个 OSD 崩溃又重启，数据是否丢失？

OSDMap 变更，PG 被迁移到了其他 OSD；

有写入操作在某些副本成功，其他副本失败；

网络分区时，PG 状态可能不一致。

为了保证这些情况之后，集群仍然是强一致性的，必须进行一次 peering 来 协商“哪个是正确的 PG 状态”。

📌 Peering 触发的典型场景：
OSD 启动或重启；

OSD 崩溃或下线；

集群新增或移除 OSD；

OSDMap 更新（比如 crush map 变化）；

重新平衡（rebalance）发生；

整个集群重启。
》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》
osd map:
OSD Map 是一个由 Monitor 维护的、描述集群拓扑和 OSD 状态的映射表，包含了所有 OSD 的健康状态、PG 到 OSD 的映射规则等关键信息。

✅ OSD Map 包含哪些信息？
信息项	说明
所有 OSD 的 ID 和状态	包括每个 OSD 是否 up/down，in/out
CRUSH 映射	用于数据分布的规则（包括权重等）
PG 到 OSD 的映射	每个 PG 应该由哪些 OSD 存储副本
版本号（epoch）	每次变动都加一，确保有序更新
Pool 信息	包括 Pool 数量、PG 数量、副本数等
历史事件（如 OSD 添加）	帮助恢复时回溯状态变化

✅ 它是干嘛用的？
客户端基于 OSD Map + CRUSH 算法可以定位对象在哪个 OSD 上（无须中心路由）；

OSD 之间通过它协调 PG 所属、副本副本一致性等；

用于 PG peering、数据恢复、迁移等重要流程；

保证集群一致性和故障恢复的关键。

✅ 举个简单例子：
假设你有：

4 个 OSD：ID 为 0~3；

有一个 Pool 设置为 64 个 PG，每个 PG 保持 2 个副本；

OSD Map 会告诉你：

OSD.2 当前是 down 状态；

PG 3 的副本在 OSD.0 和 OSD.2；

PG 3 需要恢复一个副本到 OSD.1，因为 OSD.2 down；

OSD.1 目前 in，且有足够空间；

客户端查询对象 hash 为 PG 3，根据 OSD Map 得知应联系 OSD.0 读取。

》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》
一个pg中有哪些不同的对象：
head 对象：当前最新版本的数据对象；

clone 对象：表示某个快照时刻的历史数据副本（实际存储了当时的对象数据）；

snapdir 对象：用于管理一个对象的快照信息元数据（不包含实际数据）。

🔄 具体分工：
类型	内容	作用
head	当前对象的最新数据	普通读写操作针对的对象
clone	每个快照时刻的对象副本	保留对象的历史数据（可以通过快照访问）
snapdir	快照列表 + clone 映射信息	记录有哪些快照、每个快照指向哪个 clone

🔍 举个例子：
你对对象 foo 打了两个快照 snap1 和 snap2，然后继续修改对象内容。

那么 Ceph 会：

把 snap1 和 snap2 时刻的对象内容分别拷贝成两个 clone（如 foo@snap1, foo@snap2）；

把这两个 clone 的元信息（它们属于哪个快照，时间戳等）写入 foo~snapdir 对象中；

继续的写操作只影响 foo（head 对象）本身，不会影响 clone。

✅ 为什么要分开存？
clone 存数据：因为快照要支持读历史数据，必须保存当时的数据版本；

snapdir 存元数据：集中管理 clone 的映射关系、快照 ID、时间戳等，方便快照遍历和恢复。

》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》
omap 用来干什么？
OMAP 主要用于存储对象的元数据，常见的用途有：

用途	示例说明
RADOSGW 元数据存储	比如 S3 的 object tag、ACL、versioning 信息等
RBD 镜像元数据	RBD 镜像快照、层结构、映射关系
CephFS 的 inode 信息	存储 inode 对象的属性（如权限、时间戳等）
Bluestore 自身内部管理用途	记录对象状态、回滚信息等

》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》
pg 读写流程
1 ）OSD 收到客户端发送的读写请求，将其封装为一个 op 并基于其携带的 PGID 转 发至相应的 PGO 

2 ）PG 收到 op 后，完成一系列检查，所有条件均满足后，开始真正执行 op。

3 ）如果 op 只包含读操作，那么直接执行同步读（对应多副本）或者异步读（对应纠 删码）， 等待读操作完成后向客户端应答。 

4 ）如果 op 包含写操作，首先由 Primary 基于 op 生成一个针对原始对象操作的事务
及相关日志，然后将其提交至 PGBackend, 由 PGBackend 按照备份策略转化为每个 PG
实例（包含 Primary 和所有 Replica）真正需要执行的本地事务并进行分发，当 Primary 收到所有副本的写入完成应答之后，
对应的 op 执行完成，此时由 Primary 向客户端回应 写入完成

》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》》
一些术语：
Acting Set 是什么？
当一个 PG（比如 pg 1.23）被映射到若干个 OSD 上时（根据 CRUSH 规则和 OSDMap），Ceph 会选出一组 OSD 来“实际执行”该 PG 的副本管理和 I/O 操作，这组 OSD 就是 Acting Set。

它包含：
Primary OSD（主副本，接收客户端请求）
Replica OSD(s)（从副本，同步主副本的写入）

为什么需要 up set？
因为 up set 是由 CRUSH 算法 + OSD map 决定的，是 PG 所属的“法定位置”：

它告诉系统 在没有故障的前提下，PG 应该在哪些 OSD 上。

它指导 peering 过程中，应该去联系哪些 OSD 获取状态。

它用于判断哪些 OSD 是 “失联的成员”，需要恢复、替换或修复。

🔹 为什么需要 acting set？
因为真实世界中 OSD 总会有宕机或丢失的可能，不能盲目信任 up set。

所以需要一个**“实际正在工作”的集合**，即 acting set：

是 peering 之后选出的、当前可用且副本一致的 OSD 集合；

所有对 PG 的 读写操作都只会在 acting set 中执行；

如果 acting set 成员少于副本数（如从 3 个降到 2 个），PG 就是 degraded 状态。

PG Peering 阶段】：建立共识，决定当前有哪些数据副本是可信的（即 acting set）
当一个 PG 所属的 OSD 重启、crash、网络变动或 OSD map 发生变化时，PG 会进入 peering 状态。

此时，系统会尝试联系 up set 中的 OSD，询问它们有没有这个 PG 的最新数据。

每个 OSD 会报告自己所持有的 PG 状态（包括 epoch、版本号等）。

Ceph 的 OSD 会根据各副本的日志、对象版本，协商出一组完整一致的 PG 副本 —— 这就是新的 acting set。

总结一句话， upset 对peering 选举有效osd 有指导作用，告诉系统中哪些osd是理论上可用的，后续peering + recover 生成 acting set 保持一致。

》》》》》》》》》》》》》》》》》》》peering + recover《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《《
✅ 说明：
up set 提供“理论上应该有哪些节点参与 peering”。
acting set 是 peering 的结果，代表“实际上哪些节点持有副本”。
2️⃣ 【Recovery 阶段】：修复 acting set 和 up set 的差异
假如 peering 发现：

up set = [1, 3, 4]（理应的数据位置）

acting set = [1, 3]（实际拥有数据）

OSD.4 是空的、健康的，那么：

系统会：

从 OSD.1 或 OSD.3 把数据 复制到 OSD.4；

等复制完成后，acting set 变为 [1, 3, 4]；

这样 acting set 就与 up set 对齐了；

最终达到 clean 状态，PG 恢复健康。


        OSD map 变更 / OSD 重启 / PG 不健康
                         ↓
                  🔄 PG 进入 Peering 状态
                         ↓
        与 up set 中的 OSD 协议协商 PG 状态、版本
                         ↓
        ➤ 如果可以确定完整一致的 PG 副本
                         ↓
        ✅ Peering 成功 → 生成新的 acting set
                         ↓
        📦 Recovery 开始：补齐 acting set 到 up set

》》》》》》》》》》》》》》》》》》》》》》》》》》》》peering是如何判断哪个副本是可用的用于后续recover
找出一组副本，它们之间在对象、日志等方面的一致性足够，能够完全重构出 PG 的数据状态。这一组副本就是可恢复的“源”，后续恢复过程会基于这组副本进行。

🔍 步骤详解：
触发 peering 的时机：

OSD crash/reboot；

网络断联；

OSDMap 更新（新增/剔除 OSD）；

主动触发，比如 admin 操作。

所有 up set 中的 OSD 上报 PG 状态：
每个 OSD 上报其持有的 PG 的：

last_update: 最后一次更新的版本；

last_complete: 最后一次“完整”状态的版本；

log: 最近的操作日志（写、删除等）；

missing set: 缺失的对象版本；

object info: 对象的元信息摘要；

epoch: 这个状态在哪个 OSDMap 时有效。

主 OSD（usually primary）分析副本状态：
它会根据：

哪些 OSD 有最近的更新（last_update 最大）；

哪些 OSD 有完整的历史记录和数据（last_complete 最一致）；

哪些副本日志内容一致；

哪些副本的 missing set 最少；
来判断出哪一组副本能组合出一个可恢复的数据快照。

选出 acting set：
主 OSD 根据上面分析，选择一组“足够一致且完整”的 OSD 作为 acting set，即：

接下来读写由这组 OSD 承担；

恢复（recovery）数据也将从这组 OSD 拉取副本同步到缺失 OSD。

✅ 举个简单例子：
假设 PG 101 有 up set = [osd.1, osd.2, osd.3]，其中：

OSD	last_update	last_complete	missing
osd.1	v.100	v.100	∅
osd.2	v.100	v.100	∅
osd.3	v.98	v.98	[v.99, v.100]

osd.1 和 osd.2 持有完整的、最新的一致副本；

osd.3 缺少两次写操作。

→ 所以 osd.1 和 osd.2 会被选入 acting set，osd.3 会作为恢复目标被重新同步。

🚨 为什么不能只看版本号？
因为有时版本号虽然相同，但：

实际内容可能被损坏（bitrot）；

日志不一致（比如有的日志未落盘）；

OSD 之间 epoch 不一致（对应不同的 OSDMap 上下文）；

所以必须综合多种因素判断，不是“最大版本号优先”。
